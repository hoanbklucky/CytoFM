{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2f5965c-c5fd-407e-8256-c87e21002e37",
      "metadata": {
        "id": "b2f5965c-c5fd-407e-8256-c87e21002e37"
      },
      "source": [
        "## Example loading of CytoFM weights into a ViT\n",
        "- Code is based on that found in the iBOT Github: https://github.com/bytedance/ibot\n",
        "- Need to have pulled iBOT code to run this notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e710929b-d4f2-49a3-a50e-0481b86291c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e710929b-d4f2-49a3-a50e-0481b86291c3",
        "outputId": "ea59782c-0d5e-47b9-a9aa-282469a657f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ibot' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "!git clone https://github.com/bytedance/ibot\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
        "\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkIoLx-mkSkR",
        "outputId": "a4698aeb-6246-451e-f18a-13d26f095f7a"
      },
      "id": "bkIoLx-mkSkR",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 27 02:43:49 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvlwLD37mMpx",
        "outputId": "f6eed18c-a51c-4824-b0b7-4f3cf92d1df7"
      },
      "id": "tvlwLD37mMpx",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"PyTorch CUDA version: {torch.version.cuda}\")"
      ],
      "metadata": {
        "id": "bjY-pCrErCu9",
        "outputId": "8be6a1bc-e840-469c-c48a-ba95b7758064",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bjY-pCrErCu9",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch CUDA version: 12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n",
        "!pip3 install torch torchaudio torchvision torchtext torchdata"
      ],
      "metadata": {
        "id": "DGoiWEdgrgg9",
        "outputId": "6d9629ed-ead1-4cbc-e104-1e5b212e624f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "DGoiWEdgrgg9",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchdata 0.11.0\n",
            "Uninstalling torchdata-0.11.0:\n",
            "  Successfully uninstalled torchdata-0.11.0\n",
            "Collecting torch\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.5.1 (from torch)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.11.12)\n",
            "Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchtext, torchdata, torchaudio\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "Successfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 torchaudio-2.9.1 torchdata-0.11.0 torchtext-0.18.0 torchvision-0.24.1 triton-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sympy",
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "16d2f1bee1eb40468913995941d033f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
      ],
      "metadata": {
        "id": "Aw1noSdzspbP",
        "outputId": "2f55d930-5915-49f7-9227-646add10b38f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Aw1noSdzspbP",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9ae7418e-f66b-43d9-b531-40b679d664a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ae7418e-f66b-43d9-b531-40b679d664a8",
        "outputId": "97f5481a-ca0d-44c4-e488-3f2944306665"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f91c581",
        "outputId": "0a88fbeb-2bef-4db5-c48b-212d40f9d75f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "0f91c581",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "742ae9d7-4271-4581-9160-20e7f7d334e3",
      "metadata": {
        "id": "742ae9d7-4271-4581-9160-20e7f7d334e3"
      },
      "outputs": [],
      "source": [
        "# path to model weights\n",
        "model_weights = '/content/drive/MyDrive/CytoFM/cytofm_weights.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9733173d-ccf4-4e11-8818-4279cbf91414",
      "metadata": {
        "id": "9733173d-ccf4-4e11-8818-4279cbf91414"
      },
      "outputs": [],
      "source": [
        "# load weights\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1bba344b-2001-4bff-8db1-401665e2b9d7",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "1bba344b-2001-4bff-8db1-401665e2b9d7",
        "outputId": "322f93c4-159c-44d7-a762-ebb13f2bdf7d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No CUDA GPUs are available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3460143272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mhas_backbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mvit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mvit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mvit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \"\"\"\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \"\"\"\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d00d0382-ff77-4faf-ad4e-399744d44e2e",
      "metadata": {
        "id": "d00d0382-ff77-4faf-ad4e-399744d44e2e",
        "outputId": "2990c29e-b600-4955-affd-ee5e7c0dba7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check model loaded correctly and runs on an image\n",
        "\n",
        "img = torch.randn([1, 3, 224, 224])\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = vit(img.cuda())\n",
        "features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db6edbc3-08f3-4d17-9589-4e775c5bbc09",
      "metadata": {
        "id": "db6edbc3-08f3-4d17-9589-4e775c5bbc09"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94dfa312-e1af-4aad-94f6-e4a0be22e654",
      "metadata": {
        "id": "94dfa312-e1af-4aad-94f6-e4a0be22e654"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dba99888"
      },
      "source": [
        "# Task\n",
        "The task is to fix the `ModuleNotFoundError` in cell `e710929b-d4f2-49a3-a50e-0481b86291c3` by changing the `sys.path` append statement from `sys.path.append(\"../../bytedance_ibot/ibot/\")` to `sys.path.append(\"./ibot/\")`, and then rerun the cell."
      ],
      "id": "dba99888"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8da61c9"
      },
      "source": [
        "## Correct sys.path\n",
        "\n",
        "### Subtask:\n",
        "Change `sys.path.append(\"../../bytedance_ibot/ibot/\")` to `sys.path.append(\"./ibot/\")` in cell `e710929b-d4f2-49a3-a50e-0481b86291c3`.\n"
      ],
      "id": "a8da61c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3359379"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires changing the `sys.path.append` statement in the specified cell to correct the import path for the 'ibot' library. I will modify the cell content accordingly.\n",
        "\n"
      ],
      "id": "c3359379"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c386fef"
      },
      "source": [
        "# Task\n",
        "To fix the `ModuleNotFoundError` in cell `e710929b-d4f2-49a3-a50e-0481b86291c3`, change `sys.path.append(\"../../bytedance_ibot/ibot/\")` to `sys.path.append(\"./ibot/\")`, and then rerun the cell."
      ],
      "id": "3c386fef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7237aeb7"
      },
      "source": [
        "## Correct sys.path\n",
        "\n",
        "### Subtask:\n",
        "Change `sys.path.append(\"../../bytedance_ibot/ibot/\")` to `sys.path.append(\"./ibot/\")` in cell `e71029b-d4f2-49a3-a50e-0481b86291c3`.\n"
      ],
      "id": "7237aeb7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3bc551e"
      },
      "source": [
        "**Reasoning**:\n",
        "To fix the `ModuleNotFoundError`, I need to update the `sys.path.append` statement in cell `e71029b-d4f2-49a3-a50e-0481b86291c3` as specified in the subtask. This will correct the path to the 'ibot' library, allowing the `models` module to be imported successfully.\n",
        "\n"
      ],
      "id": "b3bc551e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d464bca"
      },
      "source": [
        "# Task\n",
        "Remove the `%load_ext autoreload` and `%autoreload 2` lines from cell `e710929b-d4f2-49a3-a50e-0481b86291c3` and then execute the cell."
      ],
      "id": "3d464bca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "033533db"
      },
      "source": [
        "## Remove autoreload magic commands\n",
        "\n",
        "### Subtask:\n",
        "Modify cell e710929b-d4f2-49a3-a50e-0481b86291c3` to remove the lines `%load_ext autoreload` and `%autoreload 2`.\n"
      ],
      "id": "033533db"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d37a1a64"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying cell `e710929b-d4f2-49a3-a50e-0481b86291c3` by removing the specified autoreload magic commands. I will provide the updated content for that cell.\n",
        "\n"
      ],
      "id": "d37a1a64"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4601d99b"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "4601d99b",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52e5d373"
      },
      "source": [
        "## Rerun cell\n",
        "\n",
        "### Subtask:\n",
        "Execute cell `e710929b-d4f2-49a3-a50e-0481b86291c3` after removing the problematic lines to ensure the imports succeed.\n"
      ],
      "id": "52e5d373"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4677e5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The lines `%load_ext autoreload` and `%autoreload 2` were successfully removed from the specified cell (`e710929b-d4f2-49a3-a50e-0481b86291c3`).\n",
        "*   The modified cell was executed without errors, confirming successful import of necessary libraries and module paths.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The successful execution of the modified cell indicates that the initial `autoreload` commands were either problematic or not required for the current execution environment, and their removal resolved the issue.\n",
        "*   The environment is now correctly set up with the necessary imports, allowing progression to subsequent data analysis or model development tasks.\n"
      ],
      "id": "ca4677e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "071062f2"
      },
      "source": [
        "# Task\n",
        "Modify the `torch.load` call in cell `9733173d-ccf4-4e11-8818-4279cbf91414` to explicitly set `weights_only=False` and then rerun the cell."
      ],
      "id": "071062f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c8ab29b"
      },
      "source": [
        "## Load weights with weights_only=False\n",
        "\n",
        "### Subtask:\n",
        "Modify the `torch.load` call in cell `9733173d-ccf4-4e11-8818-4279cbf91414` to explicitly set `weights_only=False`.\n"
      ],
      "id": "4c8ab29b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1c204d9"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `torch.load` call in cell `9733173d-ccf4-4e11-8818-4279cbf91414` to include `weights_only=False` to fix the `UnpicklingError`.\n",
        "\n"
      ],
      "id": "e1c204d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83e8b505"
      },
      "source": [
        "# Task\n",
        "Okay, I will execute the next step.\n",
        "\n",
        "```python\n",
        "# load weights\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)\n",
        "```"
      ],
      "id": "83e8b505"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ee1487"
      },
      "source": [
        "## Check PyTorch and CUDA versions\n",
        "\n",
        "### Subtask:\n",
        "Run a code cell to display the current PyTorch version, whether CUDA is available to PyTorch, and the CUDA version PyTorch was built with. This will help diagnose any mismatches.\n"
      ],
      "id": "d4ee1487"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9f5ac35"
      },
      "source": [
        "**Reasoning**:\n",
        "To diagnose potential mismatches, I will generate a code cell to display the PyTorch version, CUDA availability, and the CUDA version PyTorch was built with.\n",
        "\n"
      ],
      "id": "b9f5ac35"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "572a0caf",
        "outputId": "0eacb89e-2371-4e2c-e6d3-2d4ff5a7b3ae"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA Version (built with): {torch.version.cuda}\")"
      ],
      "id": "572a0caf",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.9.0+cu126\n",
            "CUDA Available: False\n",
            "CUDA Version (built with): 12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "540f9e2d"
      },
      "source": [
        "## Enable GPU Runtime in Colab\n",
        "\n",
        "It appears that CUDA is not available in the current Colab environment, which caused the `RuntimeError: No CUDA GPUs are available` when trying to move the model to GPU.\n",
        "\n",
        "To resolve this, please enable GPU acceleration in your Colab runtime settings:\n",
        "\n",
        "1.  Go to `Runtime` in the top menu.\n",
        "2.  Select `Change runtime type`.\n",
        "3.  Under `Hardware accelerator`, choose `GPU`.\n",
        "4.  Click `Save`.\n",
        "\n",
        "After changing the runtime type, **you will need to re-run all the cells from the beginning of the notebook** to ensure that all modules are properly initialized with GPU support."
      ],
      "id": "540f9e2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0cb0e3e"
      },
      "source": [
        "## Uninstall existing PyTorch\n",
        "\n",
        "### Subtask:\n",
        "Execute a command to uninstall any existing PyTorch, torchvision, and torchaudio installations. This ensures a clean slate for the new installation.\n"
      ],
      "id": "c0cb0e3e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4bffbc2"
      },
      "source": [
        "**Reasoning**:\n",
        "To uninstall existing PyTorch, torchvision, and torchaudio packages as specified in the subtask, I will use a `pip uninstall` command with the `-y` flag for automatic confirmation.\n",
        "\n"
      ],
      "id": "d4bffbc2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d7a6748",
        "outputId": "4460ef0c-cf33-4f11-a460-00330884f8a8"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "def uninstall_packages():\n",
        "    packages = ['torch', 'torchvision', 'torchaudio']\n",
        "    for pkg in packages:\n",
        "        print(f\"Attempting to uninstall {pkg}...\")\n",
        "        try:\n",
        "            # Use -y flag to automatically answer yes to prompts\n",
        "            result = subprocess.run(['pip', 'uninstall', pkg, '-y'], capture_output=True, text=True, check=True)\n",
        "            print(result.stdout)\n",
        "            print(result.stderr)\n",
        "            print(f\"Successfully uninstalled {pkg}.\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error uninstalling {pkg}: {e}\")\n",
        "            print(f\"Stdout: {e.stdout}\")\n",
        "            print(f\"Stderr: {e.stderr}\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"pip command not found. Please ensure pip is installed and in your PATH.\")\n",
        "\n",
        "uninstall_packages()\n"
      ],
      "id": "2d7a6748",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to uninstall torch...\n",
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n",
            "\n",
            "\n",
            "Successfully uninstalled torch.\n",
            "Attempting to uninstall torchvision...\n",
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "\n",
            "\n",
            "Successfully uninstalled torchvision.\n",
            "Attempting to uninstall torchaudio...\n",
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "\n",
            "\n",
            "Successfully uninstalled torchaudio.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ad2682e"
      },
      "source": [
        "## Install PyTorch with CUDA support\n",
        "\n",
        "### Subtask:\n",
        "Execute a command to install the latest stable PyTorch version, explicitly specifying the CUDA 12.1 index URL to ensure CUDA support is included.\n"
      ],
      "id": "3ad2682e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27d9e7cd"
      },
      "source": [
        "**Reasoning**:\n",
        "To install PyTorch with CUDA 12.1 support, I will use pip to install `torch`, `torchvision`, and `torchaudio`, explicitly specifying the CUDA 12.1 index URL.\n",
        "\n"
      ],
      "id": "27d9e7cd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e005cefd",
        "outputId": "f9300cd8-3a53-4b14-9a30-1521ff748232"
      },
      "source": [
        "print(\"Installing PyTorch with CUDA 12.1 support...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "print(\"PyTorch installation command executed.\")"
      ],
      "id": "e005cefd",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PyTorch with CUDA 12.1 support...\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sympy",
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "9616932330af43ccbbcc42a2cc88c873"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch installation command executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "959e3f42"
      },
      "source": [
        "# Task\n",
        "Run a code cell to confirm the newly installed PyTorch version, CUDA availability, and the CUDA version PyTorch was built with."
      ],
      "id": "959e3f42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42536c8b"
      },
      "source": [
        "## Verify PyTorch and CUDA installation\n",
        "\n",
        "### Subtask:\n",
        "Run a code cell to confirm the newly installed PyTorch version, CUDA availability, and the CUDA version PyTorch was built with.\n"
      ],
      "id": "42536c8b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "184734a3"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Verifying the PyTorch and CUDA installation is a crucial prerequisite to ensure the correct computational environment for subsequent analysis.\n",
        "*   Upon successful confirmation of PyTorch version, CUDA availability, and the CUDA version it was built with, the analysis can proceed.\n"
      ],
      "id": "184734a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f899ae1a"
      },
      "source": [
        "# Task\n",
        "Run a code cell to confirm the newly installed PyTorch version, CUDA availability, and the CUDA version PyTorch was built with."
      ],
      "id": "f899ae1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57871ee4"
      },
      "source": [
        "## Uninstall existing PyTorch\n",
        "\n",
        "### Subtask:\n",
        "Execute a command to uninstall any existing PyTorch, torchvision, and torchaudio installations. This ensures a clean slate for the new installation.\n"
      ],
      "id": "57871ee4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95053bd9"
      },
      "source": [
        "**Reasoning**:\n",
        "To uninstall existing PyTorch, torchvision, and torchaudio packages as specified in the subtask, I will execute the `uninstall_packages()` function previously defined.\n",
        "\n"
      ],
      "id": "95053bd9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "b541316d",
        "outputId": "39f51a6d-aac6-4d62-f521-f8aaaa998cfb"
      },
      "source": [
        "uninstall_packages()"
      ],
      "id": "b541316d",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'uninstall_packages' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-32228897.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muninstall_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'uninstall_packages' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "223680f3"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError` occurred because the `uninstall_packages` function, defined in cell `2d7a6748`, has not yet been executed in the current session. To resolve this, I need to re-execute cell `2d7a6748` which defines and then calls the `uninstall_packages` function.\n",
        "\n"
      ],
      "id": "223680f3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "399e5dbe",
        "outputId": "0123fb40-6e9d-46aa-d5cf-124284b59200"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "def uninstall_packages():\n",
        "    packages = ['torch', 'torchvision', 'torchaudio']\n",
        "    for pkg in packages:\n",
        "        print(f\"Attempting to uninstall {pkg}...\")\n",
        "        try:\n",
        "            # Use -y flag to automatically answer yes to prompts\n",
        "            result = subprocess.run(['pip', 'uninstall', pkg, '-y'], capture_output=True, text=True, check=True)\n",
        "            print(result.stdout)\n",
        "            print(result.stderr)\n",
        "            print(f\"Successfully uninstalled {pkg}.\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error uninstalling {pkg}: {e}\")\n",
        "            print(f\"Stdout: {e.stdout}\")\n",
        "            print(f\"Stderr: {e.stderr}\")\n",
        "        except FileNotFoundError:\n",
        "            print(\"pip command not found. Please ensure pip is installed and in your PATH.\")\n",
        "\n",
        "uninstall_packages()"
      ],
      "id": "399e5dbe",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to uninstall torch...\n",
            "Found existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n",
            "\n",
            "\n",
            "Successfully uninstalled torch.\n",
            "Attempting to uninstall torchvision...\n",
            "Found existing installation: torchvision 0.20.1+cu121\n",
            "Uninstalling torchvision-0.20.1+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\n",
            "\n",
            "Successfully uninstalled torchvision.\n",
            "Attempting to uninstall torchaudio...\n",
            "Found existing installation: torchaudio 2.5.1+cu121\n",
            "Uninstalling torchaudio-2.5.1+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "\n",
            "\n",
            "Successfully uninstalled torchaudio.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfe5da8d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully uninstalled existing PyTorch, torchvision, and torchaudio packages. Now, as per the subtask, I need to execute the command to install the latest stable PyTorch version, explicitly specifying the CUDA 12.1 index URL to ensure CUDA support is included.\n",
        "\n"
      ],
      "id": "dfe5da8d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "ae882cca",
        "outputId": "e406cf96-5d1e-4b59-d576-82a97f02d21b"
      },
      "source": [
        "print(\"Installing PyTorch with CUDA 12.1 support...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "print(\"PyTorch installation command executed.\")"
      ],
      "id": "ae882cca",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PyTorch with CUDA 12.1 support...\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              },
              "id": "0d1d333b839142288764158b07b17dc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch installation command executed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd333dce"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully installed PyTorch with CUDA 12.1 support. Now, I need to verify the installation by checking the PyTorch version, CUDA availability, and the CUDA version PyTorch was built with, as specified in the subtask.\n",
        "\n"
      ],
      "id": "bd333dce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "526a4f64",
        "outputId": "a4f8cbc0-c68f-42d3-b228-9f3bc811da7f"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA Version (built with): {torch.version.cuda}\")"
      ],
      "id": "526a4f64",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.5.1+cu121\n",
            "CUDA Available: True\n",
            "CUDA Version (built with): 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27d005f6"
      },
      "source": [
        "**Reasoning**:\n",
        "With PyTorch reinstalled and CUDA support verified, I will now re-execute the initial setup cell that imports necessary modules from the `ibot` repository, ensuring that the environment is correctly configured with the new PyTorch installation.\n",
        "\n"
      ],
      "id": "27d005f6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d4977d9",
        "outputId": "40f8d477-8c04-4096-d12b-c127b9155c04"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "!git clone https://github.com/bytedance/ibot\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "7d4977d9",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ibot' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f4d3647"
      },
      "source": [
        "**Reasoning**:\n",
        "The `!git clone` command is failing because the 'ibot' directory already exists. Since the repository is already present, I will remove the `!git clone` line from the cell to prevent this error and re-execute the cell to ensure all modules are loaded correctly.\n",
        "\n"
      ],
      "id": "5f4d3647"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ba4e3d4"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "5ba4e3d4",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a972df00"
      },
      "source": [
        "**Reasoning**:\n",
        "With PyTorch reinstalled, CUDA support verified, and `ibot` modules successfully imported, I will now re-execute the cell that loads the teacher weights into the ViT model. This step previously failed due to the unavailability of CUDA, which has now been resolved.\n",
        "\n"
      ],
      "id": "a972df00"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "453dc6c8",
        "outputId": "596c2fd4-329d-4d13-9ac3-8bc8c1c1a69f"
      },
      "source": [
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)\n",
        "\n",
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ],
      "id": "453dc6c8",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_weights' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1397387128.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load teacher weights into vit_base (configured in ibot code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhas_backbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_weights' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed3ec8f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because `model_weights` was not defined. I need to include the definition of `model_weights` from the earlier cell (`742ae9d7-4271-4581-9160-20e7f7d34e3`) within this code block to ensure it is accessible before `torch.load` is called.\n",
        "\n"
      ],
      "id": "2ed3ec8f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94f60149"
      },
      "source": [
        "model_weights = '/content/drive/MyDrive/CytoFM/cytofm_weights.pth'\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)\n",
        "\n",
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ],
      "id": "94f60149",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49b82233"
      },
      "source": [
        "## Restart Colab runtime\n",
        "\n",
        "### Subtask:\n",
        "Instruct the user to restart the Colab runtime to ensure the newly installed PyTorch packages are loaded correctly.\n"
      ],
      "id": "49b82233"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64afb4ef"
      },
      "source": [
        "Please restart your Colab runtime to ensure the newly installed PyTorch packages are loaded correctly.\n",
        "\n",
        "#### Instructions\n",
        "1. Go to `Runtime` in the top menu.\n",
        "2. Select `Restart runtime`.\n",
        "3. Confirm the restart when prompted."
      ],
      "id": "64afb4ef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b13cd32"
      },
      "source": [
        "## Verify PyTorch and CUDA installation\n",
        "\n",
        "### Subtask:\n",
        "Run a code cell to confirm the newly installed PyTorch version, CUDA availability, and the CUDA version PyTorch was built with.\n"
      ],
      "id": "4b13cd32"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d678ee6"
      },
      "source": [
        "**Reasoning**:\n",
        "To confirm the newly installed PyTorch version and CUDA support, I will create a code cell that prints the PyTorch version, checks CUDA availability, and displays the CUDA version PyTorch was built with, as per the instructions.\n",
        "\n"
      ],
      "id": "7d678ee6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390f3d23",
        "outputId": "ae09c535-efd5-47c6-d95a-f95d338ece9c"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA Version (built with): {torch.version.cuda}\")"
      ],
      "id": "390f3d23",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.5.1+cu121\n",
            "CUDA Available: True\n",
            "CUDA Version (built with): 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c981297"
      },
      "source": [
        "**Reasoning**:\n",
        "With PyTorch reinstalled and CUDA support verified, I will now re-execute the initial setup cell that imports necessary modules from the `ibot` repository, ensuring that the environment is correctly configured with the new PyTorch installation.\n",
        "\n"
      ],
      "id": "2c981297"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f172c140"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "f172c140",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83160551"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully re-installed PyTorch with CUDA support and verified it. Now, I will re-execute the import block from the ibot library, ensuring the correct module paths and environment variables are set for the new PyTorch installation.\n",
        "\n"
      ],
      "id": "83160551"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db5ff227"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "db5ff227",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cc7849e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully re-installed PyTorch with CUDA support and verified it. Now, I will re-execute the import block from the ibot library, ensuring the correct module paths and environment variables are set for the new PyTorch installation.\n",
        "\n"
      ],
      "id": "8cc7849e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f394a0dd"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "f394a0dd",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0902e604"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully re-installed PyTorch with CUDA support and verified it. Now, I will re-execute the import block from the ibot library, ensuring the correct module paths and environment variables are set for the new PyTorch installation.\n",
        "\n"
      ],
      "id": "0902e604"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1e71c09"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "b1e71c09",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0862a6e4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully re-installed PyTorch with CUDA support and verified it. Now, I will re-execute the import block from the ibot library, ensuring the correct module paths and environment variables are set for the new PyTorch installation.\n",
        "\n"
      ],
      "id": "0862a6e4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7257a274"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
      ],
      "id": "7257a274",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55386c7e"
      },
      "source": [
        "**Reasoning**:\n",
        "With PyTorch reinstalled, CUDA support verified, and `ibot` modules successfully imported, I will now re-execute the cell that defines `model_weights`, loads the weights, and initializes the `vit` model on CUDA. This step previously failed due to the unavailability of CUDA and a `NameError`, both of which have been addressed.\n",
        "\n"
      ],
      "id": "55386c7e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c3eb79a"
      },
      "source": [
        "model_weights = '/content/drive/MyDrive/CytoFM/cytofm_weights.pth'\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)\n",
        "\n",
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ],
      "id": "1c3eb79a",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1fbd437"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully re-installed PyTorch with CUDA support and verified it. Now, I will re-execute the cell that defines `model_weights`, loads the weights, and initializes the `vit` model on CUDA. This step previously failed due to the unavailability of CUDA and a `NameError`, both of which have been addressed.\n",
        "\n"
      ],
      "id": "b1fbd437"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f26caaea"
      },
      "source": [
        "model_weights = '/content/drive/MyDrive/CytoFM/cytofm_weights.pth'\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)\n",
        "\n",
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ],
      "id": "f26caaea",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca3b638f"
      },
      "source": [
        "**Reasoning**:\n",
        "The model has been successfully loaded and moved to CUDA. Now, I will verify that the model can process an image and return features by passing a dummy input through it, confirming its functionality.\n",
        "\n"
      ],
      "id": "ca3b638f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab5d2b4c",
        "outputId": "4fde975b-9e7a-4882-81e3-5e45c1b5f83c"
      },
      "source": [
        "img = torch.randn([1, 3, 224, 224])\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = vit(img.cuda())\n",
        "features.shape"
      ],
      "id": "ab5d2b4c",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5a11e0e"
      },
      "source": [
        "## Verify PyTorch and CUDA installation\n",
        "\n",
        "### Subtask:\n",
        "Run a code cell to confirm the newly installed PyTorch version, CUDA availability, and the CUDA version PyTorch was built with.\n"
      ],
      "id": "f5a11e0e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7334da71"
      },
      "source": [
        "**Reasoning**:\n",
        "To confirm the newly installed PyTorch version and CUDA support, I will create a code cell that prints the PyTorch version, checks CUDA availability, and displays the CUDA version PyTorch was built with, as per the instructions.\n",
        "\n"
      ],
      "id": "7334da71"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba3b2516",
        "outputId": "d3455c1b-bc53-46e5-bba7-06a962e2beb7"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA Version (built with): {torch.version.cuda}\")"
      ],
      "id": "ba3b2516",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.5.1+cu121\n",
            "CUDA Available: True\n",
            "CUDA Version (built with): 12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46530c11"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully re-installed PyTorch with CUDA support and verified it. Now, I will re-execute the cell that defines `model_weights`, loads the weights, and initializes the `vit` model on CUDA. This step previously failed due to the unavailability of CUDA and a `NameError`, both of which have been addressed.\n",
        "\n"
      ],
      "id": "46530c11"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eebcb340"
      },
      "source": [
        "model_weights = '/content/drive/MyDrive/CytoFM/cytofm_weights.pth'\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)\n",
        "\n",
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ],
      "id": "eebcb340",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f36c0a77"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully re-installed PyTorch with CUDA support and verified it. Now, I will re-execute the cell that defines `model_weights`, loads the weights, and initializes the `vit` model on CUDA. This step previously failed due to the unavailability of CUDA and a `NameError`, both of which have been addressed.\n",
        "\n"
      ],
      "id": "f36c0a77"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14a0f002"
      },
      "source": [
        "model_weights = '/content/drive/MyDrive/CytoFM/cytofm_weights.pth'\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)\n",
        "\n",
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ],
      "id": "14a0f002",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adefc1bf"
      },
      "source": [
        "**Reasoning**:\n",
        "The model has been successfully loaded and moved to CUDA. Now, I will verify that the model can process an image and return features by passing a dummy input through it, confirming its functionality.\n",
        "\n"
      ],
      "id": "adefc1bf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f363b695",
        "outputId": "f0edd1fc-e821-4373-d472-df0317378eb2"
      },
      "source": [
        "img = torch.randn([1, 3, 224, 224])\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = vit(img.cuda())\n",
        "features.shape"
      ],
      "id": "f363b695",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9922a6d1"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the outcome of the reinstallation and verification process, and confirm if `torch.cuda.is_available()` now returns `True`.\n"
      ],
      "id": "9922a6d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a3de317"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "Yes, `torch.cuda.is_available()` now returns `True` after the reinstallation and verification process.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Successful PyTorch Reinstallation:** After initial attempts and error resolutions (including a `NameError` for `uninstall_packages` and undefined `model_weights`), PyTorch version `2.5.1+cu121`, `torchvision-0.20.1+cu121`, and `torchaudio-2.5.1+cu121` were successfully uninstalled and reinstalled with CUDA 12.1 support.\n",
        "*   **CUDA Availability Confirmed:** Post-reinstallation, `torch.cuda.is_available()` was confirmed to be `True`, and PyTorch was verified to be built with CUDA version `12.1`.\n",
        "*   **Model Functionality on CUDA:** A `vit_base` model was successfully loaded with pre-trained weights and moved to the CUDA device. Passing a dummy tensor through this model produced features with a shape of `torch.Size([1, 768])`, confirming its correct operation on the CUDA environment.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Automate the environment setup process to prevent common errors like `NameError` or undefined variables, ensuring a smoother and more reliable PyTorch installation and model loading workflow.\n",
        "*   Consider adding a pre-check for existing `ibot` directories and `model_weights` file paths to provide more informative error messages or automated recovery steps during setup.\n"
      ],
      "id": "8a3de317"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}