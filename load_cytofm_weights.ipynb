{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b2f5965c-c5fd-407e-8256-c87e21002e37",
      "metadata": {
        "id": "b2f5965c-c5fd-407e-8256-c87e21002e37"
      },
      "source": [
        "## Example loading of CytoFM weights into a ViT\n",
        "- Code is based on that found in the iBOT Github: https://github.com/bytedance/ibot\n",
        "- Need to have pulled iBOT code to run this notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e710929b-d4f2-49a3-a50e-0481b86291c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e710929b-d4f2-49a3-a50e-0481b86291c3",
        "outputId": "ea59782c-0d5e-47b9-a9aa-282469a657f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/hoan-ngo/miniconda3/envs/torch/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/hoan-ngo/miniconda3/envs/torch/lib/python3.14/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/home/hoan-ngo/miniconda3/envs/torch/lib/python3.14/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import torch\n",
        "\n",
        "#!git clone https://github.com/bytedance/ibot\n",
        "sys.path.append(\"/home/hoan-ngo/Documents/AI4Thyroid/Models/ibot/\")\n",
        "\n",
        "\n",
        "from models import VisionTransformer, vit_tiny, vit_small, vit_base, vit_large\n",
        "from models import SwinTransformer, swin_tiny, swin_small, swin_base\n",
        "\n",
        "\n",
        "\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bkIoLx-mkSkR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkIoLx-mkSkR",
        "outputId": "a4698aeb-6246-451e-f18a-13d26f095f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Dec 28 20:46:54 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3060        Off |   00000000:01:00.0  On |                  N/A |\n",
            "|  0%   57C    P5             25W /  170W |     657MiB /  12288MiB |     16%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A            2949      G   /usr/lib/xorg/Xorg                      245MiB |\n",
            "|    0   N/A  N/A            3329      G   /usr/bin/gnome-shell                     46MiB |\n",
            "|    0   N/A  N/A            4423      G   /usr/bin/nautilus                        26MiB |\n",
            "|    0   N/A  N/A            4464      G   ...nap-store/1270/bin/snap-store         22MiB |\n",
            "|    0   N/A  N/A            4971      G   .../6565/usr/lib/firefox/firefox         19MiB |\n",
            "|    0   N/A  N/A            9836      G   ...rack-uuid=3190708988185955192         42MiB |\n",
            "|    0   N/A  N/A           18563      G   /usr/bin/gnome-control-center            13MiB |\n",
            "|    0   N/A  N/A           21889      G   /proc/self/exe                           97MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9ae7418e-f66b-43d9-b531-40b679d664a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ae7418e-f66b-43d9-b531-40b679d664a8",
        "outputId": "97f5481a-ca0d-44c4-e488-3f2944306665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version: 2.9.1+cu130\n",
            "CUDA Available: True\n",
            "CUDA Version (built with): 13.0\n"
          ]
        }
      ],
      "source": [
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA Version (built with): {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "742ae9d7-4271-4581-9160-20e7f7d334e3",
      "metadata": {
        "id": "742ae9d7-4271-4581-9160-20e7f7d334e3"
      },
      "outputs": [],
      "source": [
        "# path to model weights\n",
        "model_weights = '/home/hoan-ngo/Documents/AI4Thyroid/Models/CytoFM_Weights/cytofm_weights.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9733173d-ccf4-4e11-8818-4279cbf91414",
      "metadata": {
        "id": "9733173d-ccf4-4e11-8818-4279cbf91414"
      },
      "outputs": [],
      "source": [
        "# load weights\n",
        "ck = torch.load(model_weights, map_location=torch.device('cpu'), weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1bba344b-2001-4bff-8db1-401665e2b9d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "1bba344b-2001-4bff-8db1-401665e2b9d7",
        "outputId": "322f93c4-159c-44d7-a762-ebb13f2bdf7d",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# load teacher weights into vit_base (configured in ibot code)\n",
        "output_dict = dict(state_dict=dict())\n",
        "has_backbone = False\n",
        "for key, value in ck['teacher'].items():\n",
        "    #print(key)\n",
        "    if key.startswith('backbone'):\n",
        "        output_dict['state_dict'][key[9:]] = value\n",
        "        has_backbone = True\n",
        "    elif key.startswith('module.backbone'):\n",
        "        output_dict['state_dict'][key[16:]] = value\n",
        "        has_backbone = True\n",
        "vit = vit_base(patch_size=16).cuda()\n",
        "vit.load_state_dict(output_dict['state_dict'], strict=True)\n",
        "vit.eval();\n",
        "for p in vit.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d00d0382-ff77-4faf-ad4e-399744d44e2e",
      "metadata": {
        "id": "d00d0382-ff77-4faf-ad4e-399744d44e2e",
        "outputId": "2990c29e-b600-4955-affd-ee5e7c0dba7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check model loaded correctly and runs on an image\n",
        "\n",
        "img = torch.randn([1, 3, 224, 224])\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = vit(img.cuda())\n",
        "features.shape"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
